{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "torch.manual_seed(2019)\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(datasets):\n",
    "    \"\"\"\n",
    "    :param datasets: list containing (X.csv, y.csv) pairs\n",
    "    :return: pair (X, y) where X is the feature sample matrix and y is the label array from combining all data\n",
    "        in datasets\n",
    "    \"\"\"\n",
    "    data = [np.loadtxt(s[0], delimiter=',') for s in datasets]\n",
    "    labels = [np.loadtxt(s[1], delimiter=',') for s in datasets]\n",
    "    X = np.vstack(data)\n",
    "    y = np.concatenate(labels, axis=None)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def sphere(X_train, X_test):\n",
    "    \"\"\"\n",
    "    :param X_train: Sample-feature matrix to sphere\n",
    "    :param X_test: Sample-feature matrix to sphere according to mean and stdev of X_train\n",
    "    :return: Tuple containing (X_train_sphered, X_test_sphered)\n",
    "    \"\"\"\n",
    "    X_train, X_test = X_train.T, X_test.T\n",
    "    a, b = X_train.shape\n",
    "    stdevs = [np.std(row) for row in X_train]  # standard deviation of each row in X\n",
    "    diag = np.diag([1 / s for s in stdevs])\n",
    "    X_train_sphered = diag.dot(X_train).dot(np.eye(b) - 1 / b * np.ones((b, b)))\n",
    "    sample_means = np.array([np.mean(row) for row in X_train])\n",
    "    sample_stds = np.array([np.std(row) for row in X_train])\n",
    "\n",
    "    # Now update X_test according to sample_means, sample_stds\n",
    "    a, b = X_test.shape\n",
    "    # print(f\"X_test shape {X_test.shape}\")\n",
    "    # print(f\"means.shape {sample_means.shape}, stds.shape {sample_stds.shape}\")\n",
    "    assert sample_stds.shape[0] == a and sample_means.shape[0] == a\n",
    "    X_test_sphered = X_test - np.column_stack([sample_means for i in range(b)])\n",
    "    X_test_sphered = X_test_sphered / np.column_stack([sample_stds for i in range(b)])\n",
    "    return X_train_sphered.T, X_test_sphered.T\n",
    "\n",
    "\n",
    "def process_data(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    :param X: 2D numpy array containing all training samples\n",
    "    :param y: 1D numpy array containing all training labels corresponding to X\n",
    "    :param test_size: fraction of samples to use for training\n",
    "    :param random_state: seed for sklearn.model_selection.train_test_split\n",
    "    :return: (X_train, X_test, y_train, y_test) tuple\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y/y.max(), test_size=test_size, random_state=random_state)\n",
    "    X_train, X_test = sphere(X_train, X_test)\n",
    "    assert X_train.shape[0] == y_train.shape[0]\n",
    "    assert X_test.shape[0] == y_test.shape[0]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = ('/ArOpt.csv', '/ArOptLabel.csv')\n",
    "set2 = ('/ArOpt15.csv', '/ArOpt15Label.csv')\n",
    "set3 = ('/Ar15.csv', '/Ar15Label.csv')\n",
    "set4 = ('/Ar25.csv', '/Ar25Label.csv')\n",
    "datasets = (set1, set2, set3, set4)\n",
    "\n",
    "X, y = read_data(datasets)\n",
    "X_train, X_test, y_train, y_test = process_data(X, y, test_size=0.2, random_state=42)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(X_train).float()\n",
    "y = torch.from_numpy(y_train).float()\n",
    "xPredicted = torch.from_numpy(X_test).float()\n",
    "yTestReal = torch.from_numpy(y_test).float()\n",
    "x, y = Variable(x), Variable(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, n_feature, n_hidden, n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = torch.nn.Linear(n_feature, n_hidden)   # hidden layer\n",
    "        self.predict = torch.nn.Linear(n_hidden, n_output)   # output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "       #  x = F.leaky_relu(self.hidden(x))\n",
    "       # x = F.leaky_relu(self.hidden(x))\n",
    "        x = self.predict(x)             # linear output\n",
    "        return x\n",
    "net = Net(n_feature=15, n_hidden=13, n_output=1) \n",
    "print(net)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.005)\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "#loss_func = torch.nn.L1Loss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 15\n",
    "hidden_sizes = [8, 5]\n",
    "output_size = 1\n",
    "# Build a feed-forward network\n",
    "net = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size))\n",
    "print(net)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.005)\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "#loss_func = torch.nn.L1Loss() \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_epoch = 40000\n",
    "lost_hist_train = np.zeros([total_epoch])\n",
    "lost_hist_eval = np.zeros([total_epoch])\n",
    "net.train()\n",
    "for t in range(total_epoch):\n",
    "\n",
    "    prediction = net(x.float())     # input x and predict based on x\n",
    "\n",
    "    loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "\n",
    "    optimizer.zero_grad()   # clear gradients for next train\n",
    "    loss.backward()         # backpropagation, compute gradients\n",
    "    optimizer.step()        # apply gradients\n",
    "    # print(loss.data.numpy())\n",
    "    lost_hist_train[t] = loss.data.numpy()\n",
    "\n",
    "    y_predict = net(xPredicted.float())  # input x and predict based on x\n",
    "\n",
    "    loss_eval = loss_func(y_predict, yTestReal)  # must be (1. nn output, 2. target)\n",
    "\n",
    "    lost_hist_eval[t] = loss_eval.data.numpy()\n",
    "\n",
    "\n",
    "t = np.linspace(0,total_epoch,total_epoch)\n",
    "\n",
    "plt.semilogy()\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('mse')\n",
    "plt.plot(t,lost_hist_train,color='b',label='train')\n",
    "plt.plot(t,lost_hist_eval,color='r',label='test')\n",
    "# plt.show()\n",
    "plt.legend()\n",
    "plt.savefig('process.svg')\n",
    "\n",
    "net.eval()\n",
    "prediction = net(x.float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "y_predict= net(xPredicted.float()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_predict)\n",
    "#mse = np.sqrt(((yTestReal.detach().numpy() - y_predict.detach().numpy())**2).mean(axis=0))\n",
    "mse = sklearn.metrics.mean_squared_error(yTestReal.detach().numpy(),y_predict.detach().numpy())\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(0,1,100)\n",
    "yy = np.linspace(0,1,100)\n",
    "plt.clf()\n",
    "plt.plot(xx,yy,label='y=x')\n",
    "plt.xlabel('y_real')\n",
    "plt.ylabel('y_predict')\n",
    "plt.plot(y.numpy(), prediction.detach().numpy(), '.',label='train')\n",
    "plt.plot(yTestReal.detach().numpy(),y_predict.detach().numpy(), 'o',label='test')\n",
    "plt.legend()\n",
    "plt.savefig('results.svg')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
